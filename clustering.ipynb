{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc63b6bf-4332-41a3-ad96-97f5374f8bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ee307bb-1eba-4771-a835-bfc93f8da5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9fbe4c2-660d-4ada-9f23-974d173a2c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>East-West Airlines is trying to learn more about its customers.  Key issues are their</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flying patterns, earning and use of frequent f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>card.  The task is to identify customer segmen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Source: Based upon real business data; company...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  East-West Airlines is trying to learn more about its customers.  Key issues are their  \\\n",
       "0  flying patterns, earning and use of frequent f...                                      \n",
       "1  card.  The task is to identify customer segmen...                                      \n",
       "2                                                NaN                                      \n",
       "3                                                NaN                                      \n",
       "4  Source: Based upon real business data; company...                                      \n",
       "\n",
       "  Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN        NaN        NaN  \n",
       "1        NaN        NaN        NaN        NaN  \n",
       "2        NaN        NaN        NaN        NaN  \n",
       "3        NaN        NaN        NaN        NaN  \n",
       "4        NaN        NaN        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_excel(\"EastWestAirlines.xlsx\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c2eb1f1-bb98-41b0-9724-91b1c8beb1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26 entries, 0 to 25\n",
      "Data columns (total 5 columns):\n",
      " #   Column                                                                                 Non-Null Count  Dtype \n",
      "---  ------                                                                                 --------------  ----- \n",
      " 0   East-West Airlines is trying to learn more about its customers.  Key issues are their  18 non-null     object\n",
      " 1   Unnamed: 1                                                                             13 non-null     object\n",
      " 2   Unnamed: 2                                                                             6 non-null      object\n",
      " 3   Unnamed: 3                                                                             13 non-null     object\n",
      " 4   Unnamed: 4                                                                             18 non-null     object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97ff9bd3-7595-465c-b32d-c750accc1ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "East-West Airlines is trying to learn more about its customers.  Key issues are their     8\n",
       "Unnamed: 1                                                                               13\n",
       "Unnamed: 2                                                                               20\n",
       "Unnamed: 3                                                                               13\n",
       "Unnamed: 4                                                                                8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90aa31ff-c894-48c5-9236-2f7a5c948898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>East-West Airlines is trying to learn more about its customers.  Key issues are their</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>flying patterns, earning and use of frequent f...</td>\n",
       "      <td>NUMBER</td>\n",
       "      <td>1</td>\n",
       "      <td>Raw</td>\n",
       "      <td>Description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       East-West Airlines is trying to learn more about its customers.  Key issues are their  \\\n",
       "count                                                  18                                      \n",
       "unique                                                 18                                      \n",
       "top     flying patterns, earning and use of frequent f...                                      \n",
       "freq                                                    1                                      \n",
       "\n",
       "       Unnamed: 1  Unnamed: 2 Unnamed: 3   Unnamed: 4  \n",
       "count          13           6         13           18  \n",
       "unique          3           3          3           18  \n",
       "top        NUMBER           1        Raw  Description  \n",
       "freq            9           3          9            1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "267232a6-05e4-4dda-88f1-528a40e94ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>East-West Airlines is trying to learn more about its customers.  Key issues are their</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>flying patterns, earning and use of frequent f...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>card.  The task is to identify customer segmen...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Source: Based upon real business data; company...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(c) 2016 Galit Shmueli and Peter Bruce</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Field Name</td>\n",
       "      <td>Data Type</td>\n",
       "      <td>Max Data Length</td>\n",
       "      <td>Raw Data or Telcom Created Field?</td>\n",
       "      <td>Description</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ID#</td>\n",
       "      <td>NUMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Telcom</td>\n",
       "      <td>Unique ID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Balance</td>\n",
       "      <td>NUMBER</td>\n",
       "      <td>8</td>\n",
       "      <td>Raw</td>\n",
       "      <td>Number of miles eligible for award travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Qual_miles</td>\n",
       "      <td>NUMBER</td>\n",
       "      <td>8</td>\n",
       "      <td>Raw</td>\n",
       "      <td>Number of miles counted as qualifying for Topf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cc1_miles</td>\n",
       "      <td>CHAR</td>\n",
       "      <td>1</td>\n",
       "      <td>Raw</td>\n",
       "      <td>Number of miles earned with freq. flyer credit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cc2_miles</td>\n",
       "      <td>CHAR</td>\n",
       "      <td>1</td>\n",
       "      <td>Raw</td>\n",
       "      <td>Number of miles earned with Rewards credit car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cc3_miles</td>\n",
       "      <td>CHAR</td>\n",
       "      <td>1</td>\n",
       "      <td>Raw</td>\n",
       "      <td>Number of miles earned with Small Business cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>note:  miles bins:</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1 = under 5,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2 = 5,000 - 10,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3 = 10,001 - 25,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4 = 25,001 - 50,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5 = over 50,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Bonus_miles</td>\n",
       "      <td>NUMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Raw</td>\n",
       "      <td>Number of miles earned from non-flight bonus t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Bonus_trans</td>\n",
       "      <td>NUMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Raw</td>\n",
       "      <td>Number of non-flight bonus transactions in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Flight_miles_12mo</td>\n",
       "      <td>NUMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Raw</td>\n",
       "      <td>Number of flight miles in the past 12 months</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Flight_trans_12</td>\n",
       "      <td>NUMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Raw</td>\n",
       "      <td>Number of flight transactions in the past 12 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Days_since_enroll</td>\n",
       "      <td>NUMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Telcom</td>\n",
       "      <td>Number of days since Enroll_date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Award?</td>\n",
       "      <td>NUMBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Telcom</td>\n",
       "      <td>Dummy variable for Last_award (1=not null, 0=n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   East-West Airlines is trying to learn more about its customers.  Key issues are their  \\\n",
       "0   flying patterns, earning and use of frequent f...                                      \n",
       "1   card.  The task is to identify customer segmen...                                      \n",
       "2                                                 NaN                                      \n",
       "4   Source: Based upon real business data; company...                                      \n",
       "5              (c) 2016 Galit Shmueli and Peter Bruce                                      \n",
       "8                                          Field Name                                      \n",
       "9                                                 ID#                                      \n",
       "10                                            Balance                                      \n",
       "11                                         Qual_miles                                      \n",
       "12                                          cc1_miles                                      \n",
       "13                                          cc2_miles                                      \n",
       "14                                          cc3_miles                                      \n",
       "15                                 note:  miles bins:                                      \n",
       "16                                                NaN                                      \n",
       "17                                                NaN                                      \n",
       "18                                                NaN                                      \n",
       "19                                                NaN                                      \n",
       "20                                        Bonus_miles                                      \n",
       "21                                        Bonus_trans                                      \n",
       "22                                  Flight_miles_12mo                                      \n",
       "23                                    Flight_trans_12                                      \n",
       "24                                  Days_since_enroll                                      \n",
       "25                                             Award?                                      \n",
       "\n",
       "   Unnamed: 1       Unnamed: 2                         Unnamed: 3  \\\n",
       "0         NaN              NaN                                NaN   \n",
       "1         NaN              NaN                                NaN   \n",
       "2         NaN              NaN                                NaN   \n",
       "4         NaN              NaN                                NaN   \n",
       "5         NaN              NaN                                NaN   \n",
       "8   Data Type  Max Data Length  Raw Data or Telcom Created Field?   \n",
       "9      NUMBER              NaN                             Telcom   \n",
       "10     NUMBER                8                                Raw   \n",
       "11     NUMBER                8                                Raw   \n",
       "12       CHAR                1                                Raw   \n",
       "13       CHAR                1                                Raw   \n",
       "14       CHAR                1                                Raw   \n",
       "15        NaN              NaN                                NaN   \n",
       "16        NaN              NaN                                NaN   \n",
       "17        NaN              NaN                                NaN   \n",
       "18        NaN              NaN                                NaN   \n",
       "19        NaN              NaN                                NaN   \n",
       "20     NUMBER              NaN                                Raw   \n",
       "21     NUMBER              NaN                                Raw   \n",
       "22     NUMBER              NaN                                Raw   \n",
       "23     NUMBER              NaN                                Raw   \n",
       "24     NUMBER              NaN                             Telcom   \n",
       "25     NUMBER              NaN                             Telcom   \n",
       "\n",
       "                                           Unnamed: 4  \n",
       "0                                                 NaN  \n",
       "1                                                 NaN  \n",
       "2                                                 NaN  \n",
       "4                                                 NaN  \n",
       "5                                                 NaN  \n",
       "8                                         Description  \n",
       "9                                           Unique ID  \n",
       "10          Number of miles eligible for award travel  \n",
       "11  Number of miles counted as qualifying for Topf...  \n",
       "12  Number of miles earned with freq. flyer credit...  \n",
       "13  Number of miles earned with Rewards credit car...  \n",
       "14  Number of miles earned with Small Business cre...  \n",
       "15                                    1 = under 5,000  \n",
       "16                                 2 = 5,000 - 10,000  \n",
       "17                                3 = 10,001 - 25,000  \n",
       "18                                4 = 25,001 - 50,000  \n",
       "19                                    5 = over 50,000  \n",
       "20  Number of miles earned from non-flight bonus t...  \n",
       "21  Number of non-flight bonus transactions in the...  \n",
       "22       Number of flight miles in the past 12 months  \n",
       "23  Number of flight transactions in the past 12 m...  \n",
       "24                   Number of days since Enroll_date  \n",
       "25  Dummy variable for Last_award (1=not null, 0=n...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.drop_duplicates()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41833b08-31d5-40c0-837c-d3f5c92f02c3",
   "metadata": {},
   "source": [
    "##### DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31b02f7c-7ce1-4ed5-ad53-0b15b3d633c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['East-West Airlines is trying to learn more about its customers.  Key issues are their',\n",
       "       'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5296653-983a-48a3-9278-facf14fa8580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  East-West Airlines is trying to learn more about its customers.  Key issues are their  \\\n",
      "0  flying patterns, earning and use of frequent f...                                      \n",
      "1  card.  The task is to identify customer segmen...                                      \n",
      "2                                                NaN                                      \n",
      "4  Source: Based upon real business data; company...                                      \n",
      "5             (c) 2016 Galit Shmueli and Peter Bruce                                      \n",
      "\n",
      "  Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN        NaN        NaN  \n",
      "1        NaN        NaN        NaN        NaN  \n",
      "2        NaN        NaN        NaN        NaN  \n",
      "4        NaN        NaN        NaN        NaN  \n",
      "5        NaN        NaN        NaN        NaN  \n",
      "Numeric columns: []\n",
      "No numeric columns found in the DataFrame\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(data.head())\n",
    "# Check if the DataFrame has any columns first\n",
    "if not data.empty:\n",
    "    # Get numeric columns\n",
    "    num_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    print(\"Numeric columns:\", num_cols)\n",
    "    \n",
    "    # Only try to describe if there are numeric columns\n",
    "    if len(num_cols) > 0:\n",
    "        print(data[num_cols].describe().transpose())\n",
    "    else:\n",
    "        print(\"No numeric columns found in the DataFrame\")\n",
    "else:\n",
    "    print(\"DataFrame is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba3e37b0-82a5-4bd8-98cb-2a4661fbc44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suggestion: plot histograms for numeric cols (univariate)\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(data[col].dropna(), bins=30,color='skyblue',edgecolor='black')\n",
    "    plt.title(f\"Histogram: {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "158b0987-4ba8-48fd-825a-7ae139eacf72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x0 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "n = len(num_cols)\n",
    "cols = 3  # number of plots per row\n",
    "rows = math.ceil(n / cols)\n",
    "\n",
    "plt.figure(figsize=(15, rows * 4))\n",
    "for i, col in enumerate(num_cols, 1):\n",
    "    plt.subplot(rows, cols, i)\n",
    "    plt.hist(data[col].dropna(), bins=30, color='lightgreen', edgecolor='black')\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d46d47e-b1ba-4e7b-9471-99d2ff9b2ba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "for i, col in enumerate(num_cols):\n",
    "    plt.subplot(3, 4, i + 1)\n",
    "    plt.hist(data[col].dropna(), bins=30)\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "70c62a96-1630-4641-b3b3-1b10bc259cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x0 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "%matplotlib inline\n",
    "num_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "rows = math.ceil(len(num_cols)/3)\n",
    "\n",
    "plt.figure(figsize=(15, 4*rows))\n",
    "for i, col in enumerate(num_cols, 1):\n",
    "    plt.subplot(rows, 3, i)\n",
    "    plt.hist(data[col].dropna(), bins=30, color='lightgreen', edgecolor='black')\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f917173-abf8-4456-85b8-ca29658414da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- imports ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- magic command for inline plotting ---\n",
    "%matplotlib inline\n",
    "\n",
    "# --- now your plotting code ---\n",
    "num_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "for col in num_cols:\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.hist(data[col].dropna(), bins=30, color='skyblue', edgecolor='black')\n",
    "    plt.title(f\"Histogram: {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eaf7dd9f-fb2e-45de-a71b-5c59ca9dc703",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'EastWestAirlines' is not one of the example datasets.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Create or load your dataset first\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# For example, you could use one of seaborn's built-in datasets:\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m data \u001b[38;5;241m=\u001b[39m sns\u001b[38;5;241m.\u001b[39mload_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEastWestAirlines\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Using iris dataset as an example\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Or load your own data:\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# data = pd.read_csv('your_data_file.csv')\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Pairplot to visualize relationships\u001b[39;00m\n\u001b[0;32m     12\u001b[0m sns\u001b[38;5;241m.\u001b[39mpairplot(data, diag_kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkde\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\seaborn\\utils.py:573\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(name, cache, data_home, **kws)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(cache_path):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m get_dataset_names():\n\u001b[1;32m--> 573\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not one of the example datasets.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    574\u001b[0m     urlretrieve(url, cache_path)\n\u001b[0;32m    575\u001b[0m full_path \u001b[38;5;241m=\u001b[39m cache_path\n",
      "\u001b[1;31mValueError\u001b[0m: 'EastWestAirlines' is not one of the example datasets."
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Create or load your dataset first\n",
    "# For example, you could use one of seaborn's built-in datasets:\n",
    "data = sns.load_dataset('EastWestAirlines')  # Using iris dataset as an example\n",
    "# Or load your own data:\n",
    "# data = pd.read_csv('your_data_file.csv')\n",
    "\n",
    "# Pairplot to visualize relationships\n",
    "sns.pairplot(data, diag_kind='kde')\n",
    "plt.suptitle(\"Pairwise Feature Relationships\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(data.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22bc9c8d-6f73-4e5f-9c13-dff93ecd2525",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No variables found for grid columns.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Pairplot to visualize relationships\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m sns\u001b[38;5;241m.\u001b[39mpairplot(data, diag_kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkde\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39msuptitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPairwise Feature Relationships\u001b[39m\u001b[38;5;124m\"\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.02\u001b[39m)\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\seaborn\\axisgrid.py:2119\u001b[0m, in \u001b[0;36mpairplot\u001b[1;34m(data, hue, hue_order, palette, vars, x_vars, y_vars, kind, diag_kind, markers, height, aspect, corner, dropna, plot_kws, diag_kws, grid_kws, size)\u001b[0m\n\u001b[0;32m   2117\u001b[0m \u001b[38;5;66;03m# Set up the PairGrid\u001b[39;00m\n\u001b[0;32m   2118\u001b[0m grid_kws\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiag_sharey\u001b[39m\u001b[38;5;124m\"\u001b[39m, diag_kind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2119\u001b[0m grid \u001b[38;5;241m=\u001b[39m PairGrid(data, \u001b[38;5;28mvars\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mvars\u001b[39m, x_vars\u001b[38;5;241m=\u001b[39mx_vars, y_vars\u001b[38;5;241m=\u001b[39my_vars, hue\u001b[38;5;241m=\u001b[39mhue,\n\u001b[0;32m   2120\u001b[0m                 hue_order\u001b[38;5;241m=\u001b[39mhue_order, palette\u001b[38;5;241m=\u001b[39mpalette, corner\u001b[38;5;241m=\u001b[39mcorner,\n\u001b[0;32m   2121\u001b[0m                 height\u001b[38;5;241m=\u001b[39mheight, aspect\u001b[38;5;241m=\u001b[39maspect, dropna\u001b[38;5;241m=\u001b[39mdropna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgrid_kws)\n\u001b[0;32m   2123\u001b[0m \u001b[38;5;66;03m# Add the markers here as PairGrid has figured out how many levels of the\u001b[39;00m\n\u001b[0;32m   2124\u001b[0m \u001b[38;5;66;03m# hue variable are needed and we don't want to duplicate that process\u001b[39;00m\n\u001b[0;32m   2125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\seaborn\\axisgrid.py:1272\u001b[0m, in \u001b[0;36mPairGrid.__init__\u001b[1;34m(self, data, hue, vars, x_vars, y_vars, hue_order, palette, hue_kws, corner, diag_sharey, height, aspect, layout_pad, despine, dropna)\u001b[0m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msquare_grid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_vars \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_vars\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x_vars:\n\u001b[1;32m-> 1272\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo variables found for grid columns.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m y_vars:\n\u001b[0;32m   1274\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo variables found for grid rows.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: No variables found for grid columns."
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pairplot to visualize relationships\n",
    "sns.pairplot(data, diag_kind='kde')\n",
    "plt.suptitle(\"Pairwise Feature Relationships\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.heatmap(data.corr(), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff2d17-65fc-442c-b0d8-0a6ed5e6c978",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efe10730-7b41-4d84-bef4-e764c0398cfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'flying patterns, earning and use of frequent flyer rewards, and use of the airline credit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20520\\3026713396.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Standardize and cluster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mscaled_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mlinkage_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlinkage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscaled_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ward'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Plot dendrogram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         \u001b[0mdata_to_wrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m             \u001b[1;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m             return_tuple = (\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    914\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 918\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    919\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    890\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \"\"\"\n\u001b[0;32m    892\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1385\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1386\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1388\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1389\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    926\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m         \"\"\"\n\u001b[0;32m    929\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"n_samples_seen_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m         X = validate_data(\n\u001b[0m\u001b[0;32m    931\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[0;32m   2940\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2941\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2944\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2945\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2947\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1052\u001b[0m                         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m                 raise ValueError(\n\u001b[0;32m   1058\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m                 \u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    835\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    838\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 839\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    841\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2149\u001b[0m     def __array__(\n\u001b[0;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m     \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2153\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2154\u001b[0m         if (\n\u001b[0;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'flying patterns, earning and use of frequent flyer rewards, and use of the airline credit'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, fcluster\n",
    "import pandas as pd\n",
    "\n",
    "# Standardize and cluster\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "linkage_matrix = linkage(scaled_data, method='ward')\n",
    "\n",
    "# Plot dendrogram\n",
    "plt.figure(figsize=(10, 5))\n",
    "dendrogram(linkage_matrix)\n",
    "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "plt.show()\n",
    "\n",
    "# Assign clusters (e.g., choose 3 clusters)\n",
    "clusters = fcluster(linkage_matrix, t=3, criterion='maxclust')\n",
    "data['HierCluster'] = clusters\n",
    "\n",
    "# Cluster summary\n",
    "cluster_summary = data.groupby('HierCluster').mean()\n",
    "print(cluster_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a369154-3486-4bdd-a6d8-0d1e4dd5fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude ID and Award? from features used for clustering\n",
    "exclude_cols = ['ID#','Award?']\n",
    "features = [c for c in num_cols if c not in exclude_cols]\n",
    "print(\"Features used for clustering:\", features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda13b0f-d813-4ecf-8453-9106b0d695e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing numeric (if any)\n",
    "for c in features:\n",
    "    if data[c].isnull().sum() > 0:\n",
    "        data[c] = data[c].fillna(data[c].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440f0763-4458-498f-8814-330447a29383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR capping\n",
    "data_feat = data[features].copy()\n",
    "for c in data_feat.columns:\n",
    "    q1 = data_feat[c].quantile(0.25)\n",
    "    q3 = data_feat[c].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    low = q1 - 1.5*iqr\n",
    "    high = q3 + 1.5*iqr\n",
    "    data_feat[c] = np.where(data_feat[c] < low, low, data_feat[c])\n",
    "    data_feat[c] = np.where(data_feat[c] > high, high, data_feat[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85815848-c691-4d6b-a373-040bb5328c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary library first\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Make sure data_feat contains data\n",
    "# For example, if data_feat is not defined or is empty:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example: Create sample data if data_feat is not defined\n",
    "# Replace this with your actual data source\n",
    "data_feat = pd.DataFrame({\n",
    "    'feature1': np.random.rand(10),\n",
    "    'feature2': np.random.rand(10)\n",
    "})\n",
    "\n",
    "# Now apply scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(data_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d652155-f675-4759-8750-ec582252af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA (2D) for visualization later\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df21a317-18ee-4edc-86a8-a1a605a5104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  K-Means experiments\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Assuming X is your data\n",
    "# Let's determine the maximum number of clusters we can use\n",
    "max_clusters = min(10, len(X) - 1)  # Ensure we don't exceed n_samples - 1\n",
    "ks = list(range(2, max_clusters + 1))  # Start from 2 clusters\n",
    "inertias = []\n",
    "sil_scores = []\n",
    "kmeans_models = {}\n",
    "\n",
    "for k in ks:\n",
    "    km = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    labels = km.fit_predict(X)\n",
    "    \n",
    "    # Check if each cluster has at least 2 samples\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    if np.all(counts >= 2):  # Only calculate silhouette if all clusters have at least 2 samples\n",
    "        inertias.append(km.inertia_)\n",
    "        sil = silhouette_score(X, labels)\n",
    "        sil_scores.append(sil)\n",
    "        kmeans_models[k] = (km, labels)\n",
    "        print(f\"k={k} -> silhouette={sil:.4f}\")\n",
    "    else:\n",
    "        print(f\"k={k} -> skipped (some clusters have only one sample)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d87f7-74d6-453d-bc9e-b315806735f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('''Insights:\n",
    "\n",
    "Clusters 0 and 2 are the most valuable groups for targeted promotions and loyalty benefits.\n",
    "\n",
    "Cluster 1 indicates potential customers to re-engage via offers or discounts.\n",
    "\n",
    "Cluster 3 represents steady, long-term members who may respond well to retention campaigns.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4f10da-2275-4954-b1ac-73836dc1332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Elbow\n",
    "ks=ks[:2]\n",
    "plt.figure()\n",
    "plt.plot(ks, inertias, marker='o')\n",
    "plt.title(\"Elbow curve (KMeans)\")\n",
    "plt.xlabel(\"k\"); plt.ylabel(\"Inertia\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4329a506-5958-484b-8efe-d2ab84c29f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot silhouette vs k\n",
    "plt.figure()\n",
    "plt.plot(ks, sil_scores, marker='o')\n",
    "plt.title(\"Silhouette scores (KMeans)\")\n",
    "plt.xlabel(\"k\"); plt.ylabel(\"Silhouette\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a1445d-6f47-4405-9ad0-3fd760af1bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose best k by silhouette\n",
    "best_k = ks[np.argmax(sil_scores)]\n",
    "best_sil = max(sil_scores)\n",
    "print(f\"Selected best_k = {best_k} with silhouette = {best_sil:.4f}\")\n",
    "\n",
    "best_km, best_labels = kmeans_models[best_k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92754e9-f74d-4568-943e-7e92b0575517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize KMeans clusters on PCA 2D\n",
    "plt.figure()\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=best_labels)\n",
    "plt.title(f\"KMeans clusters (k={best_k}) on PCA (2D)\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d731b96-ef98-4850-b2b2-ebc28b98c9ed",
   "metadata": {},
   "source": [
    "#####  Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a023c26c-ba37-4fa5-a0a4-138f1d335359",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(X, method='ward')\n",
    "plt.figure(figsize=(12,5))\n",
    "# truncated dendrogram for readability\n",
    "dendrogram(Z, truncate_mode='level', p=5)\n",
    "plt.title(\"Hierarchical dendrogram (truncated)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea17b88f-53bc-42c7-b937-709c3eed10c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 4-cluster cut for interpretation\n",
    "hc = AgglomerativeClustering(n_clusters=4, linkage='ward')\n",
    "hc_labels = hc.fit_predict(X)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_pca[:,0], X_pca[:,1], c=hc_labels)\n",
    "plt.title(\"Hierarchical clustering (4 clusters) on PCA\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d28883-77d6-4f3a-b8a2-1ed53b92fa40",
   "metadata": {},
   "source": [
    "##### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276a4542-04b4-4256-9600-f55ac12bb2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_list = np.linspace(0.3, 2.0, 10)   # scaled-space eps candidates\n",
    "min_samples_list = [3,4,5,6,8]\n",
    "best_db = None\n",
    "best_db_score = -1\n",
    "best_db_params = None\n",
    "results = []\n",
    "for eps in eps_list:\n",
    "    for ms in min_samples_list:\n",
    "        db = DBSCAN(eps=eps, min_samples=ms)\n",
    "        labels = db.fit_predict(X)\n",
    "        unique_labels = set(labels)\n",
    "        n_clusters = len([lab for lab in unique_labels if lab != -1])\n",
    "        if n_clusters >= 2:\n",
    "            try:\n",
    "                score = silhouette_score(X, labels)\n",
    "            except:\n",
    "                score = -1\n",
    "        else:\n",
    "            score = -1\n",
    "        results.append({'eps': eps, 'min_samples': ms, 'n_clusters': n_clusters, 'silhouette': score})\n",
    "        if score > best_db_score:\n",
    "            best_db_score = score\n",
    "            best_db = labels.copy()\n",
    "            best_db_params = (eps, ms)\n",
    "\n",
    "res_df = pd.DataFrame(results).sort_values(by='silhouette', ascending=False)\n",
    "print(\"Top DBSCAN configurations by silhouette:\")\n",
    "print(res_df.head(10))\n",
    "if best_db_params:\n",
    "    print(\"Best DBSCAN:\", best_db_params, \"silhouette:\", best_db_score)\n",
    "\n",
    "    # visualize\n",
    "    plt.figure()\n",
    "    plt.scatter(X_pca[:,0], X_pca[:,1], c=best_db)\n",
    "    plt.title(f\"DBSCAN best (eps={best_db_params[0]:.3f}, min_samples={best_db_params[1]})\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No DBSCAN configuration found with >=2 clusters in the grid tried.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13175a18-9121-4846-bd66-db8adf8bd735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append cluster assignments to original data and save\n",
    "data_out = data.copy().reset_index(drop=True)\n",
    "data_out['KMeans_cluster'] = len(best_labels)\n",
    "data_out['Hierarchical_cluster_4'] = len(hc_labels)\n",
    "data_out['DBSCAN_cluster'] = len(best_db) if best_db is not None else np.nan\n",
    "\n",
    "out_csv = \"EastWestAirlines_clusters.csv\"\n",
    "data_out.to_csv(out_csv, index=False)\n",
    "print(\"Saved clustering output to:\", out_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962d48eb-1ef0-4b42-8f2c-85dcf8910ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic cluster profiling (for KMeans best_k)\n",
    "\n",
    "profile = data_out.groupby('KMeans_cluster')[features].mean().transpose()\n",
    "print(\"\\nCluster profile (feature means per KMeans cluster):\")\n",
    "print(profile)\n",
    "\n",
    "# Save profile summary\n",
    "profile.to_csv(\"KMeans_cluster_profile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d575242d-58bc-4445-8d30-bf6a21874183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# --- K-Means Silhouette ---\n",
    "kmeans_silhouette = silhouette_score(X, best_labels)\n",
    "print(f\"K-Means Silhouette Score: {kmeans_silhouette:.4f}\")\n",
    "\n",
    "# --- DBSCAN Silhouette ---\n",
    "# Only compute if DBSCAN produced 2 or more clusters\n",
    "if best_db is not None:\n",
    "    unique_labels = set(best_db)\n",
    "    n_clusters = len([lab for lab in unique_labels if lab != -1])\n",
    "    if n_clusters >= 2:\n",
    "        dbscan_silhouette = silhouette_score(X, best_db)\n",
    "        print(f\"DBSCAN Silhouette Score: {dbscan_silhouette:.4f}\")\n",
    "    else:\n",
    "        print(\"DBSCAN did not produce enough clusters for a valid silhouette score.\")\n",
    "else:\n",
    "    print(\"DBSCAN not executed or produced only one cluster.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4e24c8-a05b-499c-b181-bc9e1694ac60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
